# 后训练 (Post-training / Fine-tuning)

## 核心内容 (Core Topics)

### 1. 监督微调 (Supervised Fine-tuning, SFT)
- Task-specific fine-tuning
- Multi-task learning
- Few-shot learning

### 2. 参数高效微调 (Parameter-Efficient Fine-tuning)
- LoRA (Low-Rank Adaptation)
- AdaLoRA
- Prefix Tuning
- Prompt Tuning
- P-Tuning v2

### 3. 强化学习人类反馈 (RLHF)
- Reward modeling
- PPO (Proximal Policy Optimization)
- DPO (Direct Preference Optimization)
- RLHF pipeline

### 4. 指令微调 (Instruction Tuning)
- Instruction dataset construction
- Alignment techniques
- Safety and helpfulness tuning

### 5. 其他后训练技术
- Continual learning
- Domain adaptation
- Model compression
- Knowledge distillation

## 代码示例 (Code Examples)

See `code/` folder for:
- LoRA implementation
- RLHF training scripts
- Instruction tuning examples
- Fine-tuning utilities

## 问题与讨论 (Questions and Discussions)

See `questions/` folder for:
- Fine-tuning vs. pre-training
- Parameter-efficient methods comparison
- RLHF implementation details
- Alignment challenges

